#!/usr/bin/env python3
"""
æµ‹è¯•Seleniumçˆ¬è™«ç­–ç•¥çš„è„šæœ¬
"""

import sys
import logging
from toutiao.crawler_selenium import ToutiaoSeleniumCrawler

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def test_selenium_crawler():
    """æµ‹è¯•Seleniumçˆ¬è™«"""
    print("ğŸš€ æµ‹è¯•Seleniumçˆ¬è™«...")
    
    try:
        # åˆå§‹åŒ–çˆ¬è™«ï¼ˆä½¿ç”¨æœ‰å¤´æ¨¡å¼ä¾¿äºè°ƒè¯•ï¼‰
        crawler = ToutiaoSeleniumCrawler(headless=False)
        
        # ä½¿ç”¨ç¤ºä¾‹åšä¸»URL
        blogger_url = "https://www.toutiao.com/c/user/token/MS4wLjABAAAAu8TLqbwurnpNAkvSb1SB60loMjrybIwxT3py56-uKRM/?source=profile&tab=article"
        
        print(f"æ­£åœ¨ä»åšä¸»URLè·å–æ–‡ç« ...")
        print(f"è®¿é—®URL: {blogger_url}")
        
        # æµ‹è¯•è·å–æ–‡ç« åˆ—è¡¨
        articles = crawler.get_articles_from_url(blogger_url, max_count=3)
        
        if articles:
            print(f"âœ… æˆåŠŸè·å– {len(articles)} ç¯‡æ–‡ç« :")
            for i, article in enumerate(articles, 1):
                print(f"\n{i}. æ ‡é¢˜: {article.get('title', 'N/A')[:80]}...")
                print(f"   æ–‡ç« ID: {article.get('article_id', 'N/A')}")
                print(f"   URL: {article.get('url', 'N/A')}")
                
                # æµ‹è¯•è·å–æ–‡ç« è¯¦æƒ…
                if article.get('article_id'):
                    print(f"   æ­£åœ¨è·å–è¯¦æƒ…...")
                    details = crawler.get_article_details(article['article_id'])
                    if details:
                        print(f"   å‘å¸ƒæ—¶é—´: {details.get('publish_time', 'N/A')}")
                        print(f"   ä½œè€…: {details.get('author', 'N/A')}")
                        print(f"   æ‘˜è¦: {details.get('summary', 'N/A')[:100]}...")
        else:
            print("âŒ æœªè·å–åˆ°æ–‡ç« ")
        
        # æµ‹è¯•è®¿é—®
        print(f"\nğŸ” æµ‹è¯•åšä¸»URLè®¿é—®...")
        can_access = crawler.test_user_access(blogger_url)
        if can_access:
            print("âœ… åšä¸»URLè®¿é—®æ­£å¸¸")
        else:
            print("âŒ åšä¸»URLè®¿é—®å¤±è´¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logging.exception("æµ‹è¯•Seleniumçˆ¬è™«å¤±è´¥")
    
    finally:
        # ç¡®ä¿æ¸…ç†èµ„æº
        if 'crawler' in locals():
            del crawler

if __name__ == '__main__':
    test_selenium_crawler()
